---
title: ESXi VMware Setup Instructions Session One
sidebar_label: ESXi VMware Setup Instructions Session One
---
This document contains Install instructions and demo walkthroughs for the Glasswall ICAP solution running on VMware.

### Pre-requisites

- ESXi 6.7 server with 300 GB or more Storage capacity
- Added 10 IP Addresses
- Internet access

### Part 1) ICAP Server and Squid Proxy

1. Download 3 OVAs mentioned below: 
    - [ICAP Server](https://glasswall-sow-ova.s3-eu-west-1.amazonaws.com/vms/ICAP-Server/k8-icap-sow-v2.ova)
    - [Proxy Rebuild](https://glasswall-sow-ova.s3-eu-west-1.amazonaws.com/vms/proxy-rebuild/proxy-rebuild-dec11.ova)
    - [File-drop](https://glasswall-sow-ova.s3-eu-west-1.amazonaws.com/vms/SOW-REST/sow-rest.ova)
2. Login to ESXi 6.7 server
3. Create PortGroup Network called VM  

     ![Alt text](https://raw.githubusercontent.com/k8-proxy/ESXI-setup-server/wiki1_doc_changes/docs/screenshots/PortGroup.png)   
4. Deploy each OVAs in ESXI 6.7 Server
   
    1. “Create/Register VMs” from OVAS (using “Deploy a virtual machine from an OVF or OVA file)
    
        ![Alt text](https://raw.githubusercontent.com/k8-proxy/ESXI-setup-server/wiki1_doc_changes/docs/screenshots/VMDeployOva.png)
        
    2.  Select "Deploy a virtual machine from an OVF or OVA file" 
        
            Give name for VM as shown in below table.
            Select respective OVA from below table in field "click to select files or drag/drop" and add downloaded OVA.
        
        | Name    | OVA | Video link |
        | :---: | :---: | :---: |
        | k8-icap-server-1 | k8-icap-sow.ova | [How to Use ICAP-Server](https://www.youtube.com/watch?v=LkYBPTpo2yw&feature=youtu.be) |
        | k8-proxy-server-1 | Proxy-Rebuild.ova | [How to Use ICAP-Proxy](https://www.youtube.com/watch?v=5rZ9rHfMvi8&feature=youtu.be)|
        | sow-rest | sow-rest.ova | [How to Use File-Drop](https://www.youtube.com/watch?v=Mq722RuMIQU&feature=youtu.be) |
        
        ![Alt text](https://raw.githubusercontent.com/k8-proxy/ESXI-setup-server/wiki1_doc_changes/docs/screenshots/VMSelectOVA.png) 
      
    3. Click next until you get below screen and finally click Finish to deploy OVA in ESXI
    
        ![Alt text](https://raw.githubusercontent.com/k8-proxy/ESXI-setup-server/wiki1_doc_changes/docs/screenshots/VMReady.png) 
  
    4. Be aware of the following errors while deploying all 3 OVAs:
    
        ![image](https://user-images.githubusercontent.com/70108899/101050857-1ee24580-3585-11eb-90e3-6701379b769a.png)

        ![image (1)](https://user-images.githubusercontent.com/70108899/101050996-489b6c80-3585-11eb-9865-f0204f00fa47.png)
    
    5. Before starting the VM, make sure a network adapter (created in step 3) is attached to the VM.

       ![image](https://raw.githubusercontent.com/k8-proxy/ESXI-setup-server/main/docs/screenshots/tempsnip.png)

    6. Start the k8-icap-server-1 VM
    7. Repeat the same process for other 2 OVA to deploy it in ESXi VMware (refer above table for VM name, OVA information and demo video)
    
5. Configure ICAP Server
    1. In ESXI, once file upload is completed, click on k8-icap-server-1 in list of VMs and open browser console for `k8-icap-server-1`
    
        ![Alt text](https://raw.githubusercontent.com/k8-proxy/ESXI-setup-server/wiki1_doc_changes/docs/screenshots/OpenConsole.png)
        
    2. You will be asked to login:
    
            glasswall login: glasswall
            password: Gl@$$wall
        
    3. Pull up date files from repository by running:
    
            cd vmware-scripts/icap-server

            git pull origin main
           
    4. Configure network interface by running:
        
            sudo ./01-network-setup.sh <ip_address/nn> <gateway_address>

            example : sudo ./01-network-setup.sh 78.159.113.47/26 78.159.113.62

            verify the change by runing: ping google.com

    5. Configure kubernetes service by running:      
       
            ./02-k8s-patch.sh
        
    6. Run health check:
    
            ./03-service-health.sh
            
           (note: if you see unhealthy status of the pods, give it few minute since RabbitMQ is slow to start)
        
     
    7. Run: 
            
            kubectl get pods -A --watch 
        
           (note: server will be operational when the adaptation-service is running ok)
    
6. Run ICAP client locally 

    1. Open local terminal window 
    2. Run:
    
            git clone https://github.com/k8-proxy/icap-client-docker.git
        
    3. Run: 
    
            cd icap-client-docker/
            sudo docker build -t c-icap-client .
        
    4. Run: 
           
            ./icap-client.sh {IP of k8-icap-server-1} JS_Siemens.pdf
            
            (check Respond Headers: HTTP/1.0 200 OK to verify rebuild is successful)
        
    5. Run: 
    
            open rebuilt/rebuilt-file.pdf  
        
           (and notice "Glasswall Proccessed" watermark on the right hand side of the page)
        
    6. Open original `./JS_Siemens.pdf` file in Adobe reader and notice the Javascript and the embedded file 
    7. Open `https://file-drop.co.uk/` or `https://glasswall-desktop.com/` and drop both files (`./JS_Siemens.pdf ( original )` and `rebuilt/rebuilt-file.pdf (rebuilt) `) and compare the differences
    
7. Run multiple requests in parallel
    1. Run: 
    
            ./parallel-icap-requests.sh {ip of  k8-icap-server-1} 10 
        
           (it will start 10 docker containers, each making an ICAP request)
        
    2. Run below command to see local containers life cycle: 

           docker stats    
    
8. Configure Nginx/Squid proxy server 

    1. In ESXI, open browser console for `k8-proxy-server-1`
    
            Login (username: glasswall, password: Gl@$$wall)
   
    2. Run below command after updating the IP address of the VM and gateway IP address
    
            sudo python3 configure_ip.py -i {IP address}/{subnet} -g {gateway IP}
            
    3. Go to `~/s-k8-proxy-rebuild/stable-src/` folder and run `setup.sh` to upgrade the helm release with the ICAP server IP address we need to use by the proxy.
           
            cd ~/s-k8-proxy-rebuild/stable-src/
            ./setup.sh <ICAP server IP>
            
    4. Run: `ping www.google.com` (to confirm that internet access is working)
             
    5. If the nginx or squid needs few DNS names to be assigned to an IP address, host aliases (below line) can be added to the setup.sh script. For example if `www.glasswallsolutions`. local and `www.glasswallsolutions.local` domains should be assigned to `192.168.56.90` IP, add below line to setup.sh script:  
               
                --set hostAliases."192\\.168\\.56\\.90"={"glasswallsolutions.local"\,"www.glasswallsolutions.local"} \
                
                
    6. Depending on which websites need the proxy, update the above command with the domain names as explained in next step ( [proxy-ip-config video](https://www.youtube.com/watch?v=Ll2PTSqcVVk&feature=youtu.be) )
9. Configure local machine to use Proxy server
    1. Open local hosts file ( /etc/hosts on Linux and OSx , C:\Windows\System32\drivers\etc\hosts on Windows)
    2. Add these entries
    
        - {IP of k8-proxy-server-1}     glasswallsolutions.com
        - {IP of k8-proxy-server-1}     owasp.org
        - {IP of k8-proxy-server-1}     www.owasp.org
        
    3. Confirm DNS mappings are ok by running following (all should point to {IP of k8-proxy-server-1})
        - ping www.glasswallsolutions.com
        - ping owasp.org
        - ping www.owasp.org
    4. Open any browser and access `www.glasswallsolutions.com` or `owasp.org`  after adding the IP address of this server to this DNS in hosts file.
    
10. Browser above websites protected by Glasswall SDK (via Glasswall ICAP server)

    1. Open `https://glasswallsolutions.com/` in browser
    
        1. Accept self signed cert (in Chrome this is done by clicking on ‘Advanced’ and then clicking on “Proceed to glasswallsolutions.com (unsafe)” 
        2. Click on the “Technology” link
        3. Click on “Download Brochure”
        4. Notice the “Glasswall Processed” watermark on the top right (used for demo purposes)
    
    2. Open https://owasp.org/ in browser
        1. Accept self-signed cert
        2. Click on Projects (opens drop down menu)
        3. Click on ‘Owasp Top Ten’
        4. Click on ‘Download’ (right-hand side menu in the “Downloads or Social Links” section)
        5. Notice the “Glasswall Processed” watermark on the top right 
        6. Back on the OWASP website, type “pdf” on the search bar (drop right)
        7. Click on the 3rd link called “PDF Archive Files” (which is this page https://owasp.org/www-pdf-archive/)
        8. Click on any of those files (for example the first one is https://owasp.org/www-pdf-archive//(Almost)_everything_about_passwords_that_OWASP_OWASPGbg_20140218_Per_Thorsheim.pdf)
        9. Notice the “Glasswall Processed” watermark and how this complex file was correctly rebuilt

### Part 2) Seeing ICAP Kubernetes pods in action

1. Start monitoring Kubernetes pods events in k8-icap-server-1 
    1. In ESXi, open browser console for k8-icap-server-1 OR ssh into vm from local terminal using:
      
            ssh glasswall@{ip of k8-icap-server-1}   
            (enter k8-icap-server-1 and accept the ECDSA key fingerprint)               
    2. Run : 
    
            kubectl get pods -A --watch
        
    3. Keep this window open for monitoring
    
2. Generate traffic
    1. Open local terminal where https://github.com/k8-proxy/icap-client-docker.git was cloned in 6th step of Part 1.
            
         (This will be reffred as  `icap-client-terminal` )
         
    2. Run:  
    
            ./icap-client.sh {ip of k8-icap-server-1} 
    
3. Switch back to `k8-icap-server-1` console to see multiple status of the pod created to process the file sent by the ./icap-client.sh tool (one pod per file processed)
   
      ![Alt text](https://raw.githubusercontent.com/k8-proxy/ESXI-setup-server/wiki1_doc_changes/docs/screenshots/icap-server-pods.png) 
      
4. Send multiple requests  
    1. Go to `icap-client-terminal`
    2. Run: 
    
            ./parallel-icap-requests.sh {ip of  k8-icap-server-1}  10
        
    3. See the multiple events in the `k8-icap-server-1` console
    
        ![Alt text](https://raw.githubusercontent.com/k8-proxy/ESXI-setup-server/wiki1_doc_changes/docs/screenshots/icap-server-pods2.png)
    
5. Browse `www.glasswallsolutions.com` or `owasp.org` websites (with the local dns changes made to the hosts file)

    1. Open any pdf

    2. See pod events in `k8-icap-server-1` console (one pod per file processed).

6. Install octant tool to see more details about kubernetes setup (for more details about Octant see https://octant.dev/ and https://github.com/vmware-tanzu/octant)
   
    1. In `k8-icap-server-1` VSXi console or in `ssh glasswall@{ IP of k8-icap-server-1 }` in local terminal
      
    2. Run: 
    
            wget https://github.com/vmware-tanzu/octant/releases/download/v0.16.2/octant_0.16.2_Linux-64bit.deb
        
    3. Run: 
           
            sudo dpkg -i octant_0.16.2_Linux-64bit.deb
        
    4. Exit console by typing `exit`
       
    5. Run below in local terminal: 
            
            ssh -L 7777:127.0.0.1:7777 glasswall@{IP of k8-icap-server-1}
        
    6. Run:
    
            octant
        
    7. Open in browser: `http://localhost:7777/#/`
    
       ![Alt text](https://raw.githubusercontent.com/k8-proxy/ESXI-setup-server/wiki1_doc_changes/docs/screenshots/octant_homescreen.png)
    
7. Use Octant UI:

    - Chose icap-adaptation from the Namespaces drop down menu (top menu, in the middle)

        - http://localhost:7777/#/workloads/namespace/icap-adaptation
        
        ![Alt text](https://raw.githubusercontent.com/k8-proxy/ESXI-setup-server/wiki1_doc_changes/docs/screenshots/octant_screen2.png)
        
    - Click on events 

        - http://localhost:7777/#/overview/namespace/icap-adaptation/events
        
       ![Alt text](https://raw.githubusercontent.com/k8-proxy/ESXI-setup-server/wiki1_doc_changes/docs/screenshots/octant_screen3.png)
       
    - Generate some traffic using `./icap-client.sh {IP of k8-icap-server-1}` or `./parallel-icap-requests.sh {IP of k8-icap-server-1} 10` in `icap-client-terminal`
    - The rebuld-* pods start creating and you can view pods creation in octant UI

        ![Alt text](https://raw.githubusercontent.com/k8-proxy/ESXI-setup-server/wiki1_doc_changes/docs/screenshots/octant_events.png)

    - Click on one of the rebuild-* pods (in the Kind column), and notice
        - Summary (for example: Pod Conditions, Environment variables, Volume Mounts, Events)
        - Resource Viewer (Graph of resources used)
        - Yaml (of Pod)
        - Logs (from inside the pod, notice the Glasswall events):
        
        ![Alt text](https://raw.githubusercontent.com/k8-proxy/ESXI-setup-server/wiki1_doc_changes/docs/screenshots/octant_event2.png)
        
    - Check logs

        ![Alt text](https://raw.githubusercontent.com/k8-proxy/ESXI-setup-server/wiki1_doc_changes/docs/screenshots/octant_logs.png)
    		
            ( Terminal of rebuild-* will be gone since pods are long gone )
    
    - To open an terminal into an running pod, try the rabbitmq-controller available from
       `http://localhost:7777/#/overview/namespace/icap-adaptation/workloads/pods`
    	
    - On the left navigation, click on Workloads and then Pods
     `http://localhost:7777/#/overview/namespace/icap-adaptation/workloads/pods`
        - Run: 
       
                ./parallel-icap-requests.sh {ip of  k8-icap-server-1}  20
                 (which will make 20 requests to the server)
             
        - Click on the ‘Age’ column to show the most recent pods at the top (they should appear when starting the Glasswall Rebuild process and disappear when completed)
       
    - Explore other parts of the UI to get more details about the setup and configuration of the Glasswall ICAP Solution.

    ### Part 3) Scale up and Load balancers

    1. ***Create VMs for Load balancers***

       -  Download 2 OVAs mentioned below:
          - [HAProxy-ICAP OVA](https://glasswall-sow-ova.s3-eu-west-1.amazonaws.com/vms/HAProxy-ICAP/HAProxy-ICAP.ova)
          - [HAProxy-Web OVA](https://glasswall-sow-ova.s3-eu-west-1.amazonaws.com/vms/HAProxy-WEB/HAProxy-WEB.ova)
       -  Open ESXi server  and select **Create/Register VMs** and choose to **Deploy a virtual machine from OVF or OVA file**

       ![image](https://user-images.githubusercontent.com/58347752/101741406-ad4d4e80-3ad2-11eb-8d57-0c3ef536bffd.png)

       - Import the download OVAs and finish installation with default configuration.

         **Note:**  Name the created machines according to the following:

         ​	- HAProxy-ICAP.ova to be named **load-balancer-icap** 

         ​	- HAProxy-Web.ova to be named **load-balancer-web**

    2. ***Setup Load Balancer for the ICAP Server***

       - From ESXi server open the console of **load-balancer-icap** VM and login with the following credentials: 

         - Username: glasswall
         - Password: Gl@$$wall

       - Run **network-conf.sh** script to configure the machine with Valid IP address, Gateway & DNS

         ```bash
         cd /home/glasswall
         sudo ./network-conf.sh
         ```

       - make sure you are connected to the Internet by running

         ```bash
         ping www.google.com
         ```

         **Note:** Rerun **network-conf.sh** script to reconfigure the network configuration or if you entered invalid data.

         **Network configuration Troubleshooting** (Optional if you want further network manipulation) 

       - Open **00-installer-config.yaml** and change IP and Gateway to an valid IP in the VM server

         ```bash
         sudo vim /etc/netplan/00-installer-config.yaml
         ```

       - then run

         ```bash
         sudo netplan apply
         ```

       - make sure you are connected to the Internet by running

         ```bash
         ping www.google.com
         ```

         ---------

       ***HAProxy Configuration*** 

       - Run **haproxy-conf.sh** script to configure the backend nodes (the servers that HAProxy forward the traffic to), you will be asked to enter the IP address of the server(s), enter the IP of **k8-icap-server-1**

         **Note:** For multi back-end nodes please remember to space separate between the records 

         ```bash
         cd /home/glasswall
         sudo ./haproxy-conf.sh
         ```

       - make sure haproxy is up and running

         ```bash
         systemctl status haproxy
         ```

       - To confirm functionality telnet your localhost on port 1344 & press 'Enter' multi times as follow

         ```bash
         telnet localhost 1344
         ```

       - It should print the following indicating server : C-ICAP/0.5.6

         ```
         Trying 127.0.0.1...
         Connected to localhost.
         Escape character is '^]'.
                         
         
         ICAP/1.0 400 Bad request
         Server: C-ICAP/0.5.6
         Connection: close
         
         Connection closed by foreign host.
         ```

         **Note:** Rerun **haproxy-conf.sh** script to reconfigure backend nodes & remember every time you run the script it rewrite the nodes and **DOESN'T APPEND**

         **HAProxy configuration Troubleshooting** (Optional if you want further configuration manipulation) 

       - open haproxy.cfg file and find the two sections that start with **#Backend nodes are those by witch HAProxy can forward requests**

         ```bash
         sudo vim /etc/haproxy/haproxy.cfg
         ```

       - Make sure only one backend node is there in both ICAP and S-ICAP sections and replace the node's IP with **k8-icap-server-1** IP.

       - Save the changes and run

         ```bash
         sudo systemctl restart haproxy
         ```

       - Run the following command to see the traffic being processed by the Load Balancer in real-time :

         ```bash
         tail -f /var/log/haproxy.log
         ```

         -----------

       - Now, from the VM where https://github.com/k8-proxy/icap-client-docker.git was cloned, open Terminal and run:

         ```bash
         cd
         ./icap-client.sh <IP of load-balancer-icap VM>
         ```

         **Note:** Remember to replace the place holders

       - This should result in a rebuild file locally 

       - One entry should appears in the HAProxy logs (showing the IP address for the request and the ICAP server that was used to process the request, in the current case since there is only one ICAP server configured, the entry should say pool/icap1)

       - Then to send 20 requests to the load balancer (all should be going to pool/icap1) run:

         ```bash
         cd
         ./parallel-icap-requests.sh <IP of load-balancer-icap VM>
         ```

         **Note:** Remember to replace the place holders

         -----------

    3. **Clone k8-icap-server-1**

       - Open ESXi server & poweroff  **k8-icap-server-1**
       - Then from the Navigator bar on the left In ESXi right click on **Storage** and select **Browse datasores** 

       ![image](https://user-images.githubusercontent.com/58347752/101751534-0a4c0300-3ad9-11eb-9cf5-43dbf2218c96.png)

       * Click on **Create Directory** and name it **_icap_servers** 
       * Select **_icap_servers** directory and create 5 new directories under it named (Note the screen-shot for illustration purposes only)
         * Server-1
         * Server-2
         * Server-3
         * Server-4
         * Server-5

       ![image](https://user-images.githubusercontent.com/58347752/101752057-b68de980-3ad9-11eb-8793-3398f12c443d.png)

       - Next, Find **k8-icap-server-1** directory and select it and press copy and choose **_icap_servers/server-1** as a target directory.

         **Note:** Do the same steps above to copy k8-icap-server-1 into the other 4 server directories

       - Close **Database Browser** and wait till copy tasks in the **Recent tasks** bar has the copies above completed successfully (Note the screen-shot for illustration purposes only)

         ![image](https://user-images.githubusercontent.com/58347752/101752371-1c7a7100-3ada-11eb-885e-df42c5a8431d.png)

       - Once copy is completed & go to **Virtual Machines** and press on **Create/Register VM** 

       - Choose to **Register an existing virtual machine** and click Next

       - Click **Select one or more virtual machines, a datastore or a directory** and choose the **_icap_server** directory

       - The 5 newly copied VMs should be shown in the table (Note the screen-shot for illustration purposes only)

       ![image](https://user-images.githubusercontent.com/58347752/101753201-06b97b80-3adb-11eb-8db4-e4ac5970d6fc.png)

       - Click Next and finish installation

       - Now back to the **Virtual Machines** list you will find 6 instances named  **k8-icap-server-1**  (Note the screen-shot for illustration purposes only)

       ![image](https://user-images.githubusercontent.com/58347752/101753760-ae36ae00-3adb-11eb-97b4-90668fd5c17b.png)

       - Starting from the second one in the list do the following:

         - Select the VM  and click on **Edit** 

         - Under **Virtual Hardware** tab expand **Hard disk 1** to figure the name of the parent directory (server-2 in the screen-shot)

           ![image](https://user-images.githubusercontent.com/58347752/101754362-5482b380-3adc-11eb-8115-65b80cbbad4b.png)

         - Open **VM Options** tab and rename the VM to be k8-icap-server-{1..5} , **k8-icap-server-2** in our scenario 

         - Save and Power on the Virtual machine

         - When the pop-up appears click on **I Copied It**

       - Next step login to each newly created VM and assign a valid new IPs

       - Open the file under /etc/netplan and add a valid IP, GW and DNS

         ```bash
         cd /etc/netplan
         sudo vim /etc/netplan/01-netcfg.yml 
         ```

         ![image](https://user-images.githubusercontent.com/58347752/101755197-45e8cc00-3add-11eb-9577-e99864a814fc.png)

       - The file should be like the screen-shot above

       - Apply your changes

         ```bash
         sudo netplan apply
         ```

       - Finally Back to **load-balancer-icap** VM and rerun **haproxy-conf.sh**   and add these new IPs to haproxy

       - Run **haproxy-conf.sh** script to configure the backend nodes (the servers that HAProxy forward the traffic to), you will be asked to enter the IP address of the server(s).

         **Note:** For multi back-end nodes please remember to space separate between the records 

         ```bash
         cd /home/glasswall
         sudo ./haproxy-conf.sh
         ```

       - make sure haproxy is up and running

         ```bash
         systemctl status haproxy
         ```

    4. ***Setup Load Balancer for Web Proxy***

       - From ESXi server open the console of **load-balancer-web** VM and login with the following credentials: 

         - Username: glasswall
         - Password: Gl@$$wall

       - Run **network-conf.sh** script to configure the machine with Valid IP address, Gateway & DNS

         ```bash
         cd /home/glasswall
         sudo ./network-conf.sh
         ```

       - make sure you are connected to the Internet by running

         ```bash
         ping www.google.com
         ```

         **Note:** Rerun **network-conf.sh** script to reconfigure the network configuration or if you entered invalid data.

         **Network configuration Troubleshooting** (Optional if you want further network manipulation) 

       - Open **00-installer-config.yaml** and change IP and Gateway to an valid IP in the VM server

         ```bash
         sudo vim /etc/netplan/00-installer-config.yaml
         ```

       - then run

         ```bash
         sudo netplan apply
         ```

       - make sure you are connected to the Internet by running

         ```bash
         ping www.google.com
         ```

         ---------

       ***HAProxy Configuration*** 

       - Run **haproxy-conf.sh** script to configure the backend nodes (the servers that HAProxy forward the traffic to), you will be asked to enter the IP address of the server(s), enter the IP of **k8-icap-proxy-1**

         **Note:** For multi back-end nodes please remember to space separate between the records 

         ```bash
         cd /home/glasswall
         sudo ./haproxy-conf.sh
         ```

       - make sure haproxy is up and running

         ```bash
         systemctl status haproxy
         ```

       - **Note:** Rerun **haproxy-conf.sh** script to reconfigure backend nodes & remember every time you run the script it rewrite the nodes and **DOESN'T APPEND**

         **HAProxy configuration Troubleshooting** (Optional if you want further configuration manipulation) 

       - open haproxy.cfg file and find the two sections that start with **#Backend nodes are those by witch HAProxy can forward requests**

         ```bash
         sudo vim /etc/haproxy/haproxy.cfg
         ```

       - Make sure only one backend node is there in both HTTP and HTTPS sections and replace the node's IP with **k8-icap-proxy-1** IP.

       - Save the changes and run

         ```bash
         sudo systemctl restart haproxy
         ```

       - Run the following command to see the traffic being processed by the Load Balancer in real-time :

         ```bash
         tail -f /var/log/haproxy.log
         ```

         -----------

       - Add hosts records to your client system hosts file ( i.e **Windows**: C:\Windows\System32\drivers\etc\hosts , **Linux, macOS and  Unix-like:** /etc/hosts ) as follows

       - Open hosts file and Change these entries to now point to the **load-balancer-web** IP address

         ```
         <IP of load-balancer-web>      glasswallsolutions.com
         <IP of load-balancer-web>      owasp.org
         <IP of load-balancer-web>      www.owasp.org
         ```

         **Note:** Please remember to replace the place holders 


### Part 4) File Drop

1. Go to VM sow-rest (File-Drop) in ESXi created in Part 1.

2. Setup File Drop configarations ( [File drop config video](https://www.youtube.com/watch?v=6HmyxAUlKH8&feature=youtu.be) )
    1. In ESXi, open browser console for sow-rest 
    
            login user :  user
            password   :  secret  
        
    2. Run: 
    
            sudo vim /etc/netplan/00-installer-config.yaml (change IP and Gateway to an valid IP in the VM server)
        
        - Replace the value: 
        
               network:
                 version: 2
                   renderer: networkd
                ethernets:
                    eth0:
                        dhcp4: yes 
           
        - With (note that this is an yaml file so that layout/spaces is import)
               
               network:
                 version: 2
                 renderer: networkd
                 ethernets:
                   eth0:
                     addresses:
                       - {IP address of file-drop}/{subnet}
                     gateway4: {IPv4 gateway of server}
                     nameservers:
                       addresses:
                           - 8.8.8.8
       Example :                   
       
       ![Alt text](https://raw.githubusercontent.com/k8-proxy/ESXI-setup-server/wiki1_doc_changes/docs/screenshots/icap-proxy-config.png)
       
    3. Run:
    
                sudo netplan apply 
       
    4. Run: `ping www.google.com` (to confirm that internet access is working)	
    
    5. Run: `sudo systemctl restart k3s`
    
    6. After reboot open https://{IP address of file-drop}
    
        ![Alt text](https://raw.githubusercontent.com/k8-proxy/ESXI-setup-server/wiki1_doc_changes/docs/screenshots/FileDrop1.png)  
        
    7. Click on Login (no password for now)
       
        ![Alt text](https://raw.githubusercontent.com/k8-proxy/ESXI-setup-server/wiki1_doc_changes/docs/screenshots/FileDrop2.png)
        
        - Drop a file in the drop zone
        - Download the Protected file 
        - Click on the ‘Refresh button’
        - Drop the protected file
        - See the difference between both files

### Part 5) ICAP Client Setup

[Download OVA for ICAP Client Setup](https://glasswall-sow-ova.s3-eu-west-1.amazonaws.com/vms/icap-client/icap_client.ova)

* run `ip a` to get the name of network interface
* change directory `cd /etc/systemd/network` and list the files in that directory `ls`, where you should see `99-static-en.network`
* edit the network file, `sudo vi 99-static-en.network`, press the letter 'i' to modify the file
  * if your network system use dhcp, change the file to dhcp mode like the example below:
    ```
    [Match]
    Name=eth0

    [Network]
    DHCP=yes
    ``` 
  * if your network system use static IP, change the file like the example below:
    ```
    [Match]
    Name=eth0

    [Network]
    Address=91.109.25.89/27
    Gateway=91.109.25.94
    DNS=8.8.8.8
    ```
  * Press 'ESC' to escape edit mode, press ':wq' to save and exit vi
* restart network service
  * run `systemctl restart systemd-networkd`
  * verify your VM's IP, `ip a`, which should look like this:
    ```
    2: eth0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc fq_codel state UP group default qlen 
    1000
    link/ether 00:0c:29:50:a3:ec brd ff:ff:ff:ff:ff:ff
    altname eno1
    altname enp11s0
    altname ens192
    inet 91.109.25.89/27 brd 91.109.25.95 scope global eth0
       valid_lft forever preferred_lft forever
    inet6 fe80::20c:29ff:fe50:a3ec/64 scope link
       valid_lft forever preferred_lft forever
	   ...
    ```
* restart docker service to enable the service
  * run `systemctl restart docker` then `docker version`, where you should expect info like this:
    ```
     Client: Docker Engine - Community
      Version:           19.03.10
      API version:       1.40
      Go version:        go1.14.8
      Git commit:        9424aea
      Built:             Tue Nov  3 22:45:58 2020
      OS/Arch:           linux/amd64
      Experimental:      false

     Server: Docker Engine - Community
      Engine:
       Version:          19.03.10
       API version:      1.40 (minimum version 1.12)
       Go version:       go1.14.8
       Git commit:       9424aea
       Built:            Tue Nov  3 22:46:58 2020
       OS/Arch:          linux/amd64
       Experimental:     false
      containerd:
      ....
    ```
* to check that docker image is ready, run `docker image ls`, which should like this:
     ```
     REPOSITORY                      TAG                 IMAGE ID            CREATED             SIZE
     c-icap-client                   latest              7ec35e673ba9        20 hours ago        1.2GB
     gcc                             latest              4d3d1ec24e9e        2 weeks ago         1.19GB
     glasswallsolutions/k8-centos7   latest              431852dc2eb5        3 weeks ago         419MB

     ```
* to test docker icap-client
  * run `cd ~`
  * Make sure you have a file ready in your directory
  * Make sure you have a stable ICAP server
  * run `docker run -v /root:/root --network host c-icap-client -i <ICAP_SERVER_IP> -p 1344 -s gw_rebuild -f /PATH/TO/TESTING/FILE.pdf -o /PATH/TO/REBUILT/OUTPUT.pdf -v`
  * the output on the terminal should look like this:
    ```
    ICAP server:54.77.168.168, ip:91.109.25.89, port:1344


    ICAP HEADERS:
        ICAP/1.0 200 OK
        Server: C-ICAP/0.5.6
        Connection: keep-alive
        ISTag: CI0001-2.1.1
        Encapsulated: res-hdr=0, res-body=207

     RESPMOD HEADERS:
        HTTP/1.0 200 OK
        Date: Wed Dec  9 15:38:51 2020
        Last-Modified: Wed Dec  9 15:38:51 2020
        Content-Length: 383912
        Via: ICAP/1.0 mvp-icap-service-5dbb694956-gccdf (C-ICAP/0.5.6 Glasswall Rebuild service )
    ```
  * to make sure your rebuilt pdf is created, run `ls -l`, where your output PDF will be smaller in byte size than the original PDF.